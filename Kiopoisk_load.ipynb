{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to https://habr.com/ru/post/467081/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Настройки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нужны реальные, чтобы не банили (смотрите свои в разделе network в инструментах разработчика браузера)\n",
    "headers = {\n",
    "    'User-Agent':'???',\n",
    "    'Accept-language' : \"*/*\",\n",
    "    'Accept' : \"ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7\"\n",
    "}\n",
    "\n",
    "# Имитация живого пользователя\n",
    "delays = [5, 6, 5.5, 5.7, 6.1, 6.3, 5.8, 4, 4.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top500_film_ids():\n",
    "    \"\"\"\n",
    "    Выкачивает с кинопоиска id фильмов из рейтинга топ 500\n",
    "    \n",
    "    Return:\n",
    "     list (str): лист id в текстовом формате \n",
    "    \"\"\"\n",
    "    ids = []\n",
    "    # На одной странице там 25 фильмов\n",
    "    for page in tqdm(range(1,21)):\n",
    "        url = f\"https://www.kinopoisk.ru/top/lists/1/filtr/all/sort/order/page/{page}/\"\n",
    "        r = requests.get(url, headers = headers) # отправка http запроса\n",
    "        soup = BeautifulSoup(r.text, 'html.parser')# создание html парсера\n",
    "        posters = soup.find_all(class_=\"poster\")\n",
    "        for poster in posters:\n",
    "            id_ = poster.find('div').get('data-film-id')\n",
    "            ids.append(id_)  \n",
    "        time.sleep(np.random.choice(delays))\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_reviews(url):\n",
    "    \"\"\"\n",
    "    Загружает все текстовые отзывы с url в текстовом формате\n",
    "    \n",
    "    Args:\n",
    "        url (str): Адрес страницы с отзывами на кинопоиске\n",
    "        \n",
    "    Return:\n",
    "        list (str): Список текстовых отзывов (отзыв помещается на одной строке)\n",
    "    \"\"\"\n",
    "    # отправка http запроса\n",
    "    r = requests.get(url, headers = headers)\n",
    "    # создание html парсера\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    # сохранение только отзывов\n",
    "    reviews = soup.find_all(class_='_reachbanner_')\n",
    "    review_converted = []\n",
    "    for review in reviews:\n",
    "        # очистка от лишней html разметки\n",
    "        review = review.find_all(text=True)\n",
    "        # приведение к строке всех найденных элементов\n",
    "        for i in review:\n",
    "            map(str, i)\n",
    "        # соединение частей отзыва в единую строку\n",
    "        review = ' '.join(review)\n",
    "        review=re.sub(\"\\n\",\" \",review)\n",
    "        review=re.sub(\"\\r\",\" \",review)\n",
    "        review_converted.append(review)\n",
    "    return review_converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(url): \n",
    "    \"\"\"\n",
    "    Получение имени фильма\n",
    "    \n",
    "    Args: \n",
    "        url (str): Адрес фильма\n",
    "        \n",
    "    Return:\n",
    "        str: Название фильма\n",
    "    \"\"\"\n",
    "    r = requests.get(url, headers = headers)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    name = soup.find(class_='alternativeHeadline')\n",
    "    name_clean = name.find_all(text = True)\n",
    "    # Сохранение первого элемента, т. к. извлекается также год фильма\n",
    "    return str(name_clean[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsing(film_url, status):\n",
    "    \"\"\"\n",
    "    Загружаем все отзывы о фильме в определенной тональности\n",
    "    \n",
    "    Args:\n",
    "        film_url (str): Адрес фильма\n",
    "        status (str): Тип тональности (доступно good, bad, neutral)\n",
    "    \n",
    "    Returns:\n",
    "        list(str): Массив текстовых отзывов (каждый отзыв не содержит переноса строки)\n",
    "    \"\"\"\n",
    "    page = 1\n",
    "    all_reviews = []\n",
    "    # Выбор рандомной задержки\n",
    "    time.sleep(np.random.choice(delays))\n",
    "    # Перебираем все страницы с отзывами к фильму\n",
    "    while True:\n",
    "        reviews = load_reviews(film_url + f'reviews/ord/rating/status/{status}/perpage/200/page/{page}/')\n",
    "        if reviews == []:\n",
    "            break\n",
    "        else:\n",
    "            all_reviews += reviews\n",
    "            page += 1\n",
    "            # Выбор рандомной задержки\n",
    "            time.sleep(np.random.choice(delays))\n",
    "            \n",
    "    return all_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_film_reviews(film_ids, statuses=['good', 'bad'], dir_='reviews', overwrite=False):\n",
    "    \"\"\"\n",
    "    Для указанных индексов фильмов загружает в файлы отзывы в такой строктуре по файлам:\n",
    "    {status}/{film_id.txt} - будут содержаться все отзывы нужного статуса по конкретному фильму\n",
    "    \n",
    "    Args:\n",
    "        film_ids (list(str)): Идентетификаторы фильмов для сохранения отзывов\n",
    "        statuses (list(str)): Статусы отзывов для сохранения\n",
    "        dir_ (str): Имя директории для сохранения\n",
    "        overwrite (bool): Если True, то перезаписывать существующие файлы\n",
    "    \"\"\"\n",
    "    \n",
    "    # Eсли папок для сохранения не существует то они создадутся\n",
    "    for status in statuses:\n",
    "        if not os.path.exists(os.path.join(dir_, status)):\n",
    "            os.makedirs(os.path.join(dir_, status))\n",
    "    \n",
    "    for film_id in tqdm(film_ids):  \n",
    "        url = f'https://www.kinopoisk.ru/film/{film_id}/'\n",
    "        for status in statuses:\n",
    "            # Путь для сохранения\n",
    "            path_save = os.path.join(dir_, status, f'{film_id}.txt')\n",
    "            # Сначала проверяем - скачивали мы этот фильм или нет\n",
    "            if os.path.exists(path_save) and not overwrite:\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                # Загружаем отзывы по фильмам\n",
    "                reviews = parsing(film_url=url, status=status)\n",
    "                # Сохраняем их\n",
    "                with open(path_save, 'w', encoding='utf-8') as filesave:\n",
    "                    filesave.write(' \\n'.join(reviews))\n",
    "                \n",
    "            # Во время бана будет получена ошибка AttributeError\n",
    "            except AttributeError:\n",
    "                print('Бан получен: {}, {}'.format(url, status))\n",
    "                break\n",
    "        # Если цикл не прерывался то продолжаем\n",
    "        else:\n",
    "            continue\n",
    "        # Выходим из цикла, если прерывалось\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_txt_files(dir_, path):\n",
    "    \"\"\"\n",
    "    Соединяет все текстовые файлы в директории в один единый\n",
    "    \n",
    "    Args:\n",
    "        dir_ (str): Директория для которой нужно выполнить операцию\n",
    "        path (str): Название итогового файла с объединением\n",
    "    \"\"\"\n",
    "    file_mask = os.path.join(dir_, \"*.txt\")\n",
    "    # Находим все подходящие файлы\n",
    "    files = glob.glob(file_mask)\n",
    "    with open(path, 'w', encoding='utf-8') as f:\n",
    "        for file in files:\n",
    "            with open(file, 'r',  encoding='utf-8') as fr:\n",
    "                f.write(fr.read())\n",
    "                # Добавим перенос строки\n",
    "                f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загружаем id топовые фильмы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45d82a3611d24d00b8e26fb1efdc03d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wall time: 2min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "top_films_ids = get_top500_film_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(top_films_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save films_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('top_films_ids.txt', 'w') as f:\n",
    "    f.write(','.join(top_films_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загружаем отзывы по категориям"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "film_ids_to_load = top_films_ids[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f69095e6a4e492f80a177e3206f3796",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wall time: 1min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "load_film_reviews(film_ids=film_ids_to_load)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Объединяем отзывы в единый файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 133 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "combine_txt_files('reviews/good', 'good_reviews.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 18 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "combine_txt_files('reviews/bad', 'bad_reviews.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
